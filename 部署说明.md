# 服务器部署说明

## 📦 必需文件清单

### 核心文件（必须上传）
1. **apple_id_crawler.py** - 主爬虫脚本
2. **main.py** - 主执行脚本
3. **github_sync.py** - GitHub同步脚本（如果使用GitHub功能）
4. **scheduler.py** - 定时任务脚本（如果需要定时运行）
5. **vpn_ads.json** - VPN广告数据文件
6. **requirements.txt** - Python依赖包列表

### 可选文件
- `simple_test.py` - 测试脚本（用于测试）
- `test.bat` - Windows测试脚本（服务器上不需要）

## 🚀 部署步骤

### 1. 上传文件到服务器
将所有必需文件上传到服务器目录，例如：`/var/www/crawler/` 或 `/home/user/crawler/`

### 2. 安装Python依赖
```bash
pip install -r requirements.txt
```

或者使用虚拟环境（推荐）：
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# 或
venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

### 3. 配置API URL（如果需要同步到网站后台）

#### 方法1：环境变量
```bash
export API_URL="http://your-domain.com/data_sync.php"
```

#### 方法2：修改代码
编辑 `main.py`，将第24行改为：
```python
api_url = "http://your-domain.com/data_sync.php"  # 你的API地址
```

### 4. 配置GitHub（如果需要GitHub同步）

如果使用GitHub功能，需要：
1. 配置Git仓库：
```bash
git init
git remote add origin https://github.com/your-username/your-repo.git
```

2. 配置Git认证（使用SSH密钥或Personal Access Token）

### 5. 测试运行

#### 测试爬虫功能
```bash
python3 simple_test.py
```

#### 运行完整流程
```bash
python3 main.py
```

#### 设置定时任务（每2小时运行一次）

**Linux使用crontab：**
```bash
crontab -e
# 添加以下行（每2小时运行一次）
0 */2 * * * cd /path/to/crawler && /usr/bin/python3 main.py >> /var/log/crawler.log 2>&1
```

**或者使用Python scheduler：**
```bash
python3 scheduler.py
```

## 📋 文件说明

### apple_id_crawler.py
- 核心爬虫类
- 负责爬取网站数据
- 格式化数据为API格式
- 同步数据到网站后台

### main.py
- 主执行脚本
- 协调爬取、同步等操作

### github_sync.py
- GitHub同步功能
- 将数据推送到GitHub仓库

### scheduler.py
- 定时任务调度
- 每2小时自动运行一次

### vpn_ads.json
- VPN广告数据
- 保持原样，不修改

## ⚙️ 配置说明

### API URL配置
如果你的网站后台API地址是：`http://example.com/data_sync.php`

设置方法：
```bash
export API_URL="http://example.com/data_sync.php"
```

### 数据格式
生成的数据格式：
```json
{
    "timestamp": 1761908869,
    "data": {
        "accounts": {
            "group1": [
                {
                    "id": "1-1",
                    "fullEmail": "xxx@xxx.com",
                    "password": "xxxxxx",
                    "status": "正常",
                    "checkTime": "2025-10-31 19:07:01",
                    "region": "US",
                    "regionName": "美国"
                }
            ],
            "group2": []
        },
        "vpn_ads": [...]
    }
}
```

## 🔍 测试检查

1. **测试爬虫**：
   ```bash
   python3 simple_test.py
   ```
   检查生成的 `api_data.json` 文件格式是否正确

2. **测试API同步**：
   确保API URL配置正确，然后运行：
   ```bash
   python3 main.py
   ```

3. **检查日志**：
   查看运行日志，确认没有错误

## ⚠️ 注意事项

1. **Python版本**：需要Python 3.7或更高版本
2. **网络连接**：确保服务器可以访问目标网站
3. **权限**：确保有写入文件的权限
4. **时区**：确保服务器时区设置正确
5. **VPN广告数据**：`vpn_ads.json` 文件需要和代码在同一目录

## 📞 问题排查

如果遇到问题：
1. 检查Python版本：`python3 --version`
2. 检查依赖安装：`pip list`
3. 查看错误日志
4. 测试网络连接：`curl https://ccbaohe.com/appleID/`

## 📝 文件结构示例

```
/var/www/crawler/
├── apple_id_crawler.py
├── main.py
├── github_sync.py
├── scheduler.py
├── simple_test.py
├── requirements.txt
├── vpn_ads.json
├── apple_ids.json          # 运行后生成
├── api_data.json           # 运行后生成
└── test_result.json        # 测试后生成
```

